"""
BA-Agent æœåŠ¡

é›†æˆ BAAgent ä¸ APIï¼Œæä¾› Agent æŸ¥è¯¢ã€å¯¹è¯ç®¡ç†ç­‰åŠŸèƒ½
"""

from typing import Optional, Dict, Any, List
from pathlib import Path
import logging
from datetime import datetime

from backend.models.response import (
    StructuredResponse,
    parse_structured_response,
    STRUCTURED_RESPONSE_SYSTEM_PROMPT,
)

logger = logging.getLogger(__name__)


class BAAgentService:
    """
    BA-Agent æœåŠ¡ç±»

    è´Ÿè´£ç®¡ç† Agent å®ä¾‹ã€å¤„ç†æŸ¥è¯¢ã€ç»´æŠ¤å¯¹è¯çŠ¶æ€
    """

    def __init__(
        self,
        model_name: str = None,
        enable_memory: bool = True,
        enable_skills: bool = True
    ):
        """
        åˆå§‹åŒ– BA-Agent æœåŠ¡

        Args:
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆé»˜è®¤ä»ç¯å¢ƒå˜é‡ BA_DEFAULT_MODEL è¯»å–ï¼Œæœ¬åœ°é»˜è®¤ glm-4.7.7ï¼‰
            enable_memory: æ˜¯å¦å¯ç”¨è®°å¿†ç³»ç»Ÿ
            enable_skills: æ˜¯å¦å¯ç”¨ Skills
        """
        import os

        # æœ¬åœ°å¼€å‘é»˜è®¤ä½¿ç”¨ GLM-4
        if model_name is None:
            model_name = os.getenv("BA_DEFAULT_MODEL", "glm-4.7")

        self.model_name = model_name
        self.model_name = model_name
        self.enable_memory = enable_memory
        self.enable_skills = enable_skills

        # å¯¹è¯çŠ¶æ€ç®¡ç†
        self._conversations: Dict[str, Dict[str, Any]] = {}

        # Agent å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self._agent = None

        logger.info(f"BAAgentService åˆå§‹åŒ–: model={model_name}, memory={enable_memory}, skills={enable_skills}")

    def initialize(self):
        """åˆå§‹åŒ– Agent å®ä¾‹"""
        try:
            from langchain.agents import create_agent
            from langgraph.checkpoint.memory import MemorySaver

            from tools import get_default_tools
            from backend.skills import SkillRegistry, SkillActivator
            from backend.api.state import get_app_state
            import os

            # æ ¹æ®æ¨¡å‹åç§°åˆ›å»ºç›¸åº”çš„æ¨¡å‹å®ä¾‹
            if self.model_name.startswith("glm-"):
                # GLM æ¨¡å‹ (æ™ºè°± AI)
                from langchain_community.chat_models import ChatZhipuAI
                model = ChatZhipuAI(
                    model=self.model_name,
                    temperature=0.7,
                    max_tokens=4096,
                    api_key=os.getenv("ZHIPUAI_API_KEY", os.getenv("GLM_API_KEY", ""))
                )
            elif self.model_name.startswith("gpt-"):
                # OpenAI æ¨¡å‹
                from langchain_openai import ChatOpenAI
                model = ChatOpenAI(
                    model=self.model_name,
                    temperature=0.7,
                    max_tokens=4096,
                    api_key=os.getenv("OPENAI_API_KEY", ""),
                    base_url=os.getenv("OPENAI_BASE_URL")
                )
            elif self.model_name.startswith("gemini-"):
                # Google Gemini æ¨¡å‹
                from langchain_google_genai import ChatGoogleGenerativeAI
                model = ChatGoogleGenerativeAI(
                    model=self.model_name,
                    temperature=0.7,
                    api_key=os.getenv("GOOGLE_API_KEY", "")
                )
            else:
                # é»˜è®¤ä½¿ç”¨ Anthropic Claude
                from langchain_anthropic import ChatAnthropic
                model = ChatAnthropic(
                    model=self.model_name,
                    temperature=0.7,
                    max_tokens=4096,
                    api_key=os.getenv("ANTHROPIC_API_KEY", ""),
                    base_url=os.getenv("ANTHROPIC_BASE_URL")
                )

            # è·å–å·¥å…·
            tools = get_default_tools()

            # å¦‚æœå¯ç”¨ Skillsï¼Œæ·»åŠ  Skills å·¥å…·
            if self.enable_skills:
                from backend.skills.skill_tool import create_skill_tool
                skill_registry = get_app_state().get("skill_registry")
                skill_activator = get_app_state().get("skill_activator")
                if skill_registry and skill_activator:
                    skill_tool = create_skill_tool(skill_registry, skill_activator)
                    if skill_tool:
                        tools.append(skill_tool)
                        logger.info("Skills å·¥å…·å·²æ·»åŠ åˆ° Agent")

            # åˆ›å»º memory
            memory = MemorySaver()

            # åˆ›å»º Agent
            self._agent = create_agent(
                model,
                tools,
                checkpointer=memory
            )

            logger.info("BAAgent å®ä¾‹åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"BAAgent åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            raise

    @property
    def agent(self):
        """è·å– Agent å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
        if self._agent is None:
            self.initialize()
        return self._agent

    def _create_model_for_request(self, model_name: str, api_key: str = None):
        """
        ä¸ºç‰¹å®šè¯·æ±‚åˆ›å»ºæ¨¡å‹å®ä¾‹

        Args:
            model_name: æ¨¡å‹åç§°
            api_key: API å¯†é’¥ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ¨¡å‹å®ä¾‹
        """
        import os

        if model_name.startswith("glm-"):
            # GLM æ¨¡å‹ (æ™ºè°± AI)
            from langchain_community.chat_models import ChatZhipuAI
            final_api_key = api_key or os.getenv("ZHIPUAI_API_KEY", os.getenv("GLM_API_KEY", ""))
            logger.info(f"åˆ›å»º ChatZhipuAI: model={model_name}, api_key_from_param={api_key is not None}, final_key_length={len(final_api_key) if final_api_key else 0}")
            return ChatZhipuAI(
                model=model_name,
                temperature=0.7,
                max_tokens=4096,
                api_key=final_api_key
            )
        elif model_name.startswith("gpt-"):
            # OpenAI æ¨¡å‹
            from langchain_openai import ChatOpenAI
            return ChatOpenAI(
                model=model_name,
                temperature=0.7,
                max_tokens=4096,
                api_key=api_key or os.getenv("OPENAI_API_KEY", ""),
                base_url=os.getenv("OPENAI_BASE_URL")
            )
        elif model_name.startswith("gemini-"):
            # Google Gemini æ¨¡å‹
            from langchain_google_genai import ChatGoogleGenerativeAI
            return ChatGoogleGenerativeAI(
                model=model_name,
                temperature=0.7,
                api_key=api_key or os.getenv("GOOGLE_API_KEY", "")
            )
        else:
            # é»˜è®¤ä½¿ç”¨ Anthropic Claude
            from langchain_anthropic import ChatAnthropic
            return ChatAnthropic(
                model=model_name,
                temperature=0.7,
                max_tokens=4096,
                api_key=api_key or os.getenv("ANTHROPIC_API_KEY", ""),
                base_url=os.getenv("ANTHROPIC_BASE_URL")
            )

    def _create_agent_for_request(self, model_name: str, api_key: str = None):
        """
        ä¸ºç‰¹å®šè¯·æ±‚åˆ›å»º Agent å®ä¾‹

        Args:
            model_name: æ¨¡å‹åç§°
            api_key: API å¯†é’¥ï¼ˆå¯é€‰ï¼‰

        Returns:
            Agent å®ä¾‹
        """
        from langchain.agents import create_agent
        from langgraph.checkpoint.memory import MemorySaver
        from tools import get_default_tools
        from backend.api.state import get_app_state

        # åˆ›å»ºæ¨¡å‹
        model = self._create_model_for_request(model_name, api_key)

        # è·å–å·¥å…·
        tools = get_default_tools()

        # å¦‚æœå¯ç”¨ Skillsï¼Œæ·»åŠ  Skills å·¥å…·
        if self.enable_skills:
            from backend.skills.skill_tool import create_skill_tool
            skill_registry = get_app_state().get("skill_registry")
            skill_activator = get_app_state().get("skill_activator")
            if skill_registry and skill_activator:
                skill_tool = create_skill_tool(skill_registry, skill_activator)
                if skill_tool:
                    tools.append(skill_tool)

        # åˆ›å»º memory
        memory = MemorySaver()

        # åˆ›å»º Agent
        return create_agent(model, tools, checkpointer=memory)

    async def query(
        self,
        message: str,
        model: Optional[str] = None,
        api_key: Optional[str] = None,
        conversation_id: Optional[str] = None,
        file_context: Optional[Dict[str, Any]] = None,
        session_id: Optional[str] = None,
        user_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œ Agent æŸ¥è¯¢

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤æ¨¡å‹ï¼‰
            api_key: API å¯†é’¥ï¼ˆå¯é€‰ï¼Œè¦†ç›–ç¯å¢ƒå˜é‡ï¼‰
            conversation_id: å¯¹è¯ ID
            file_context: æ–‡ä»¶ä¸Šä¸‹æ–‡
            session_id: ä¼šè¯ ID
            user_id: ç”¨æˆ· ID

        Returns:
            Agent å“åº”ç»“æœ
        """
        try:
            import time
            import traceback
            start_time = time.time()

            # ç¡®å®šä½¿ç”¨çš„ Agent
            agent_to_use = self.agent
            model_to_log = self.model_name

            # å¦‚æœæŒ‡å®šäº†æ¨¡å‹æˆ– API Keyï¼Œåˆ›å»ºä¸´æ—¶ Agent
            if model or api_key:
                effective_model = model or self.model_name
                logger.info(f"åˆ›å»ºåŠ¨æ€ Agent: model={effective_model}, api_key_provided={api_key is not None}, api_key_length={len(api_key) if api_key else 0}")
                agent_to_use = self._create_agent_for_request(effective_model, api_key)
                model_to_log = effective_model
            else:
                logger.info(f"ä½¿ç”¨é»˜è®¤ Agent: model={self.model_name}")

            # ç¡®ä¿å¯¹è¯å­˜åœ¨
            if not conversation_id:
                conversation_id = self._create_conversation(user_id, session_id)

            # æ„å»ºæ¶ˆæ¯
            messages = self._build_messages(message, file_context)

            # æ„å»ºé…ç½®
            config = {
                "configurable": {
                    "thread_id": conversation_id
                }
            }

            # è°ƒç”¨ Agent
            logger.info(f"Agent æŸ¥è¯¢: model={model_to_log}, conversation_id={conversation_id}, message={message[:100]}...")

            result = agent_to_use.invoke(
                {"messages": messages},
                config=config
            )

            # å¤„ç†å“åº”
            duration_ms = (time.time() - start_time) * 1000

            # æ›´æ–°å¯¹è¯çŠ¶æ€
            self._update_conversation(conversation_id, {
                "last_message_at": datetime.utcnow().isoformat() + "Z",
                "message_count": self._conversations[conversation_id]["message_count"] + 1
            })

            # æå–å“åº”å†…å®¹ï¼ˆè¿”å›å…ƒç»„ï¼šdisplay_content, structured_responseï¼‰
            display_content, structured_response = self._extract_response_content(result)

            # æ„å»ºå…ƒæ•°æ®
            metadata = {
                "content_type": "text",
                "has_structured_response": structured_response is not None
            }

            if structured_response:
                # ä»ç»“æ„åŒ–å“åº”ä¸­æå–å…ƒæ•°æ®
                metadata["action_type"] = structured_response.action.type
                metadata["current_round"] = structured_response.current_round
                metadata["task_analysis"] = structured_response.task_analysis
                metadata["execution_plan"] = structured_response.execution_plan

                # æ ¹æ®åŠ¨ä½œç±»å‹è®¾ç½®ä¸åŒçš„å…ƒæ•°æ®
                if structured_response.is_tool_call():
                    # å·¥å…·è°ƒç”¨çŠ¶æ€
                    tool_calls = structured_response.get_tool_calls()
                    metadata["tool_calls"] = [
                        {
                            "tool_name": tc.tool_name,
                            "tool_call_id": tc.tool_call_id,
                            "arguments": tc.arguments
                        }
                        for tc in tool_calls
                    ]
                    metadata["status"] = "processing"

                elif structured_response.is_complete():
                    # å®ŒæˆçŠ¶æ€
                    final_report = structured_response.get_final_report()
                    has_html = '<div' in final_report or '<script' in final_report or 'echarts' in final_report.lower()
                    metadata["contains_html"] = has_html
                    metadata["content_type"] = "html" if has_html else "text"

                    # æ¨èé—®é¢˜å’Œä¸‹è½½é“¾æ¥
                    if structured_response.action.recommended_questions:
                        metadata["recommended_questions"] = structured_response.action.recommended_questions
                    if structured_response.action.download_links:
                        metadata["download_links"] = structured_response.action.download_links

                    metadata["status"] = "complete"

            return {
                "response": display_content,
                "conversation_id": conversation_id,
                "duration_ms": duration_ms,
                "tool_calls": self._extract_tool_calls(result),
                "artifacts": self._extract_artifacts(result),
                "metadata": metadata
            }

        except Exception as e:
            import json
            error_type = type(e).__name__
            error_msg = str(e)
            error_traceback = traceback.format_exc()

            # è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
            logger.error(
                f"Agent æŸ¥è¯¢å¤±è´¥: "
                f"type={error_type}, "
                f"msg={error_msg}, "
                f"model={model_to_log if 'model_to_log' in locals() else 'unknown'}, "
                f"conversation_id={conversation_id}, "
                f"traceback={error_traceback}"
            )

            # æ„å»ºé”™è¯¯è¯¦æƒ…
            error_detail = {
                "error_type": error_type,
                "error_message": error_msg,
                "model": model_to_log if 'model_to_log' in locals() else self.model_name,
            }

            # å°è¯•ä» httpx.HTTPStatusError ä¸­æå–çœŸå® API å“åº”
            raw_api_error = None
            zhipu_error = None

            # httpx.HTTPStatusError æœ‰ response å±æ€§
            if error_type == "HTTPStatusError" and hasattr(e, 'response'):
                try:
                    response_text = e.response.text
                    logger.info(f"API åŸå§‹å“åº”: {response_text}")

                    # å°è¯•è§£æ JSON å“åº”
                    response_json = json.loads(response_text)
                    if 'error' in response_json:
                        zhipu_error = response_json['error']
                        error_detail["zhipu_code"] = zhipu_error.get('code')
                        error_detail["zhipu_message"] = zhipu_error.get('message')
                        raw_api_error = f"[{zhipu_error.get('code')}] {zhipu_error.get('message')}"
                except:
                    raw_api_error = response_text if 'response_text' in locals() else None

            # å¦‚æœæ²¡æœ‰æå–åˆ°æ™ºè°±é”™è¯¯ï¼Œå°è¯•å…¶ä»–æ–¹å¼
            if not zhipu_error:
                # æ£€æŸ¥ LangChain å¼‚å¸¸
                if hasattr(e, '__cause__') and e.__cause__:
                    raw_api_error = str(e.__cause__)

            if raw_api_error:
                error_detail["raw_error"] = raw_api_error

            # æ·»åŠ å»ºè®®
            if zhipu_error:
                code = zhipu_error.get('code', '')
                if code == '1113':
                    error_detail["suggestion"] = "æ™ºè°± AI è´¦æˆ·ä½™é¢ä¸è¶³ï¼Œè¯·å……å€¼: https://bigmodel.cn/usercenter/balance"
                elif code == '1000':
                    error_detail["suggestion"] = "æ™ºè°± AI èº«ä»½éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®"
                elif code == '1301':
                    error_detail["suggestion"] = "æ™ºè°± AI è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•"
                else:
                    error_detail["suggestion"] = f"æ™ºè°± AI é”™è¯¯: {zhipu_error.get('message')}"
            elif "429" in error_msg:
                error_detail["suggestion"] = "API è¿”å› 429 é”™è¯¯ï¼Œå¯èƒ½æ˜¯è´¦æˆ·ä½™é¢ä¸è¶³æˆ–è¯·æ±‚è¿‡äºé¢‘ç¹ã€‚è¯·æ£€æŸ¥æ‚¨çš„è´¦æˆ·ä½™é¢: https://bigmodel.cn/usercenter/balance"
            elif "401" in error_msg or "authentication" in error_msg.lower():
                error_detail["suggestion"] = "API è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®"
            elif "timeout" in error_msg.lower():
                error_detail["suggestion"] = "è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
            elif "connection" in error_msg.lower():
                error_detail["suggestion"] = "ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®"

            # è¿”å›é”™è¯¯ï¼Œä¼˜å…ˆæ˜¾ç¤ºåŸå§‹ API é”™è¯¯
            response_msg = raw_api_error if raw_api_error else error_msg
            return {
                "response": f"æŸ¥è¯¢å¤±è´¥: {response_msg}",
                "conversation_id": conversation_id,
                "error": error_detail
            }

    def _create_conversation(
        self,
        user_id: Optional[str],
        session_id: Optional[str]
    ) -> str:
        """åˆ›å»ºæ–°å¯¹è¯"""
        import uuid
        conversation_id = f"conv_{uuid.uuid4().hex[:12]}"

        self._conversations[conversation_id] = {
            "conversation_id": conversation_id,
            "user_id": user_id or "anonymous",
            "session_id": session_id or "default",
            "created_at": datetime.utcnow().isoformat() + "Z",
            "message_count": 0,
            "last_message_at": None
        }

        logger.info(f"åˆ›å»ºæ–°å¯¹è¯: {conversation_id}")
        return conversation_id

    def _build_messages(
        self,
        message: str,
        file_context: Optional[Dict[str, Any]]
    ) -> List[Dict[str, str]]:
        """æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«ç»“æ„åŒ–å“åº”ç³»ç»Ÿæç¤º"""
        messages = []

        # æ·»åŠ ç»“æ„åŒ–å“åº”ç³»ç»Ÿæç¤º
        messages.append({
            "role": "system",
            "content": STRUCTURED_RESPONSE_SYSTEM_PROMPT
        })

        # æ·»åŠ æ–‡ä»¶ä¸Šä¸‹æ–‡
        if file_context and "file_id" in file_context:
            file_ref = f"upload:{file_context['file_id']}"
            messages.append({
                "role": "system",
                "content": f"ç”¨æˆ·å·²ä¸Šä¼ æ–‡ä»¶ï¼Œæ–‡ä»¶å¼•ç”¨: {file_ref}"
            })

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        messages.append({
            "role": "user",
            "content": message
        })

        return messages

    def _extract_response_content(
        self,
        result: Dict[str, Any]
    ) -> tuple[str, Optional[StructuredResponse]]:
        """
        æå–å“åº”å†…å®¹å¹¶è§£æç»“æ„åŒ–å“åº”

        Returns:
            (display_content, structured_response)
            - display_content: ç”¨äºæ˜¾ç¤ºçš„å†…å®¹ï¼ˆHTML æˆ–æ–‡æœ¬ï¼‰
            - structured_response: è§£æåçš„ç»“æ„åŒ–å“åº”å¯¹è±¡
        """
        try:
            messages = result.get("messages", [])
            raw_content = None

            if messages:
                # è·å–æœ€åä¸€æ¡ AI æ¶ˆæ¯
                for msg in reversed(messages):
                    if hasattr(msg, 'content'):
                        content = msg.content
                        if isinstance(content, list):
                            # å¤„ç†å¤šæ¨¡æ€å†…å®¹
                            raw_content = "\n".join(
                                item.get("text", str(item))
                                for item in content
                                if isinstance(item, dict)
                            )
                        else:
                            raw_content = str(content)
                        break
                    elif isinstance(msg, dict) and "content" in msg:
                        raw_content = str(msg["content"])
                        break

            if not raw_content:
                return "æ— å“åº”å†…å®¹", None

            # è§£æç»“æ„åŒ–å“åº”
            structured_response = parse_structured_response(raw_content)

            if structured_response is None:
                # è§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹
                logger.warning(f"æ— æ³•è§£æç»“æ„åŒ–å“åº”ï¼Œè¿”å›åŸå§‹å†…å®¹")
                return raw_content, None

            # æ ¹æ®å“åº”ç±»å‹æ„å»ºæ˜¾ç¤ºå†…å®¹
            display_parts = []

            # æ·»åŠ æ€ç»´é“¾åˆ†æï¼ˆå¯æŠ˜å ï¼‰
            if structured_response.task_analysis:
                display_parts.append(f"""
<div class="task-analysis" style="margin-bottom: 12px; padding: 10px; background: #f0f7ff; border-left: 3px solid #2196F3; border-radius: 4px;">
    <details>
        <summary style="cursor: pointer; font-weight: 500; color: #1976D2;">ğŸ’¡ æ€ç»´é“¾åˆ†æ</summary>
        <div style="margin-top: 8px; font-size: 13px; color: #555; white-space: pre-wrap;">{structured_response.task_analysis}</div>
    </details>
</div>
""")

            # æ·»åŠ æ‰§è¡Œè®¡åˆ’
            if structured_response.execution_plan:
                display_parts.append(f"""
<div class="execution-plan" style="margin-bottom: 12px; padding: 10px; background: #fff3e0; border-left: 3px solid #FF9800; border-radius: 4px;">
    <div style="font-weight: 500; color: #E65100; margin-bottom: 4px;">ğŸ“‹ æ‰§è¡Œè®¡åˆ’</div>
    <div style="font-size: 13px; color: #555;">{structured_response.execution_plan}</div>
</div>
""")

            # æ ¹æ®åŠ¨ä½œç±»å‹å¤„ç†å†…å®¹
            if structured_response.is_tool_call():
                # å·¥å…·è°ƒç”¨çŠ¶æ€
                tool_calls = structured_response.get_tool_calls()
                tool_names = [tc.tool_name for tc in tool_calls]

                display_parts.append(f"""
<div class="tool-call-status" style="padding: 12px; background: #e3f2fd; border-radius: 6px; text-align: center;">
    <div style="display: inline-flex; align-items: center; gap: 8px;">
        <span class="loading-spinner" style="display: inline-block; width: 16px; height: 16px; border: 2px solid #2196F3; border-top-color: transparent; border-radius: 50%; animation: spin 1s linear infinite;"></span>
        <span style="color: #1976D2; font-weight: 500;">æ­£åœ¨æ‰§è¡Œ: {', '.join(tool_names)}</span>
    </div>
</div>
<style>
@keyframes spin {{ to {{ transform: rotate(360deg); }} }}
</style>
""")

            elif structured_response.is_complete():
                # å®ŒæˆçŠ¶æ€ï¼Œæ˜¾ç¤ºæœ€ç»ˆæŠ¥å‘Š
                final_report = structured_response.get_final_report()

                # æ£€æµ‹æ˜¯å¦åŒ…å« HTML
                has_html = '<div' in final_report or '<script' in final_report

                if has_html:
                    # åŒ…å« HTMLï¼ˆå¦‚å›¾è¡¨ï¼‰ï¼Œç›´æ¥æ¸²æŸ“
                    display_parts.append(f"""
<div class="final-report">
    {final_report}
</div>
""")
                else:
                    # çº¯æ–‡æœ¬æŠ¥å‘Šï¼Œæ ¼å¼åŒ–æ˜¾ç¤º
                    display_parts.append(f"""
<div class="final-report" style="line-height: 1.6;">
    {final_report.replace('\\n', '<br>')}
</div>
""")

                # æ·»åŠ æ¨èé—®é¢˜
                if structured_response.action.recommended_questions:
                    questions_html = '<br>'.join(
                        f'<button class="recommended-question" style="display: block; width: 100%; text-align: left; padding: 10px; margin: 6px 0; background: #f5f5f5; border: 1px solid #ddd; border-radius: 6px; cursor: pointer; transition: all 0.2s;" onclick="document.getElementById(\\'agent-query\\').value=this.textContent;document.getElementById(\\'agent-query\\').focus();">ğŸ’¡ {q}</button>'
                        for q in structured_response.action.recommended_questions
                    )
                    display_parts.append(f"""
<div class="recommended-questions" style="margin-top: 16px; padding: 12px; background: #f9f9f9; border-radius: 6px;">
    <div style="font-weight: 500; color: #333; margin-bottom: 8px;">ğŸ¤” æ¨èé—®é¢˜</div>
    {questions_html}
</div>
""")

                # æ·»åŠ ä¸‹è½½é“¾æ¥
                if structured_response.action.download_links:
                    links_html = '<br>'.join(
                        f'<a href="/api/v1/files/download/{filename}" style="display: inline-block; padding: 8px 16px; margin: 4px; background: #4CAF50; color: white; text-decoration: none; border-radius: 4px;">ğŸ“¥ {filename}</a>'
                        for filename in structured_response.action.download_links
                    )
                    display_parts.append(f"""
<div class="download-links" style="margin-top: 12px; padding: 12px; background: #e8f5e9; border-radius: 6px;">
    <div style="font-weight: 500; color: #2E7D32; margin-bottom: 8px;">ğŸ“¦ å¯ä¸‹è½½æ–‡ä»¶</div>
    {links_html}
</div>
""")

            display_content = "\n".join(display_parts)

            # æ£€æµ‹æ˜¯å¦åŒ…å« HTML å†…å®¹
            has_html = structured_response.is_complete() and (
                '<div' in display_content or '<script' in display_content or
                'echarts' in display_content.lower()
            )

            # å¦‚æœåŒ…å« HTMLï¼Œæ·»åŠ æ ‡è®°
            if has_html:
                display_content = f"<!-- HAS_HTML -->{display_content}"

            return display_content, structured_response

        except Exception as e:
            logger.error(f"æå–å“åº”å†…å®¹å¤±è´¥: {e}", exc_info=True)
            return f"å“åº”è§£æå¤±è´¥: {str(e)}", None

    def _extract_tool_calls(self, result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æå–å·¥å…·è°ƒç”¨ä¿¡æ¯"""
        tool_calls = []

        try:
            messages = result.get("messages", [])
            for msg in messages:
                if hasattr(msg, 'tool_calls'):
                    for call in msg.tool_calls:
                        tool_calls.append({
                            "tool": call.get("name", "unknown"),
                            "input": call.get("args", {}),
                            "id": call.get("id", "")
                        })
        except Exception as e:
            logger.error(f"æå–å·¥å…·è°ƒç”¨å¤±è´¥: {e}")

        return tool_calls

    def _extract_artifacts(self, result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æå–ç”Ÿæˆçš„å·¥ä»¶"""
        artifacts = []

        try:
            messages = result.get("messages", [])
            for msg in messages:
                if hasattr(msg, 'content'):
                    content = msg.content
                    if isinstance(content, list):
                        for item in content:
                            if isinstance(item, dict) and "artifact_id" in item:
                                artifacts.append(item)
        except Exception as e:
            logger.error(f"æå–å·¥ä»¶å¤±è´¥: {e}")

        return artifacts

    def _update_conversation(self, conversation_id: str, updates: Dict[str, Any]):
        """æ›´æ–°å¯¹è¯çŠ¶æ€"""
        if conversation_id in self._conversations:
            self._conversations[conversation_id].update(updates)

    def get_conversation(self, conversation_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å¯¹è¯ä¿¡æ¯"""
        return self._conversations.get(conversation_id)

    def get_conversation_history(
        self,
        conversation_id: str,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """è·å–å¯¹è¯å†å²"""
        # TODO: ä» MemoryStore æˆ– checkpointer è·å–å®Œæ•´å†å²
        # è¿™é‡Œè¿”å›åŸºæœ¬ä¿¡æ¯
        conversation = self.get_conversation(conversation_id)
        if not conversation:
            return []

        # æ¨¡æ‹Ÿè¿”å›éƒ¨åˆ†å†å²
        return [
            {
                "conversation_id": conversation_id,
                "created_at": conversation["created_at"],
                "message_count": conversation["message_count"]
            }
        ]

    def end_conversation(self, conversation_id: str) -> bool:
        """ç»“æŸå¯¹è¯"""
        if conversation_id in self._conversations:
            # æ ‡è®°ä¸ºå·²ç»“æŸ
            self._conversations[conversation_id]["status"] = "ended"
            self._conversations[conversation_id]["ended_at"] = datetime.utcnow().isoformat() + "Z"
            logger.info(f"å¯¹è¯å·²ç»“æŸ: {conversation_id}")
            return True
        return False

    def get_status(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        return {
            "agent_initialized": self._agent is not None,
            "model_name": self.model_name,
            "enable_memory": self.enable_memory,
            "enable_skills": self.enable_skills,
            "active_conversations": len([
                c for c in self._conversations.values()
                if c.get("status") != "ended"
            ]),
            "total_conversations": len(self._conversations)
        }


__all__ = ["BAAgentService"]
